## 线程

### 谈谈你对线程安全的理解

资料来源：[谈谈你对线程安全的理解](https://www.toutiao.com/video/7085655943110722062/?from_scene=all)

Hi， 大家好， 我是 Mic
一个工作了 4 年的小伙伴， 遇到了一个非常抽象的面试题， 说说你对线程安全性
的理解。
这类问题， 对于临时刷面试题来面试的小伙伴， 往往是致命的。
一个是不知道从何说起， 也就是语言组织比较困难。
其次就是， 如果对于线程安全性没有一定程度的理解， 一般很难说出你的理解。
ok， 我们来看看这个问题的回答。  

#### 高手

简单来说， 在多个线程访问某个方法或者对象的时候， 不管通过任何的方式调用以及线程如何去交替执行。
在程序中不做任何同步干预操作的情况下， 这个方法或者对象的执行/修改都能按照预期的结果来反馈， 那么这个类就是线程安全的。
实际上， 线程安全问题的具体表现体现在三个方面， 原子性、 有序性、 可见性。
原子性呢， 是指当一个线程执行一系列程序指令操作的时候， 它应该是不可中断的， 因为一旦出现中断， 站在多线程的视角来看， 这一系列的程序指令会出现前后执行结果不一致的问题。
这个和数据库里面的原子性是一样的， 简单来说就是一段程序只能由一个线程完整的执行完成， 而不能存在多个线程干扰。
CPU 的 上 下 文 切 换 ， 是 导 致 原 子 性 问 题 的 核 心 ， 而 JVM 里 面 提 供 了Synchronized 关键字来解决原子性问题  

![image-20231225153939801](img/image-20231225153939801.png)

可见性， 就是说在多线程环境下， 由于读和写是发生在不同的线程里面， 有可能出现某个线程对共享变量的修改， 对其他线程不是实时可见的。
导致可见性问题的原因有很多， 比如 CPU 的高速缓存、 CPU 的指令重排序、 编译器的指令重排序。
有序性， 指的是程序编写的指令顺序和最终 CPU 运行的指令顺序可能出现不一致的现象， 这种现象也可以称为指令重排序， 所以有序性也会导致可见性问题。
可见性和有序性可以通过 JVM 里面提供了一个 Volatile 关键字来解决。
在我看来， 导致有序性、 原子性、 可见性问题的本质， 是计算机工程师为了最大化提升 CPU 利用率导致的。 比如为了提升 CPU 利用率， 设计了三级缓存、 设计了 StoreBuffer、 设计了缓存行这种预读机制、 在操作系统里面， 设计了线程模型、 在编译器里面， 设计了编译器的深度优化机制。
一上就是我对这个问题的理解。  

#### 面试点评

从高手的回答中， 可以很深刻的感受到， 他对于计算机底层原理和线程安全性相
关的底层实现是理解得很透彻的。

对我来说， 这个人去写程序代码， 不用担心他滥用线程导致一些不可预测的线程安全性问题了， 这就是这个面试题的价值。
好的， 本期的普通人 VS 高手面试系列的视频就到这里结束了， 喜欢的朋友记得点赞和收藏。
另外， 这些面试题我都整理成了笔记， 大家有需要的可以私信获取。
我是 Mic， 一个工作了 14 年的 Java 程序员， 咱们下期再见  

### 什么是守护线程，它有什么特点？

资料来源：[什么是守护线程，它有什么特点？](https://www.toutiao.com/video/7101505375253299748/?from_scene=all)

守护线程， 它是一种专门为用户线程提供服务的线程， 它的生命周期依赖于用户线程。<br/>
只有 JVM 中仍然还存在用户线程正在运行的情况下， 守护线程才会有存在的意义。<br/>
否则， 一旦 JVM 进程结束， 那守护线程也会随之结束。<br/>
也就是说， 守护线程不会阻止 JVM 的退出。 但是用户线程会！<br/>
守护线程和用户线程的创建方式是完全相同的， 我们只需要调用用户线程里面的setDaemon 方法并且设置成 true， 就表示这个线程是守护线程。<br/>
因为守护线程拥有自己结束自己生命的特性， 所以它适合用在一些后台的通用服务场景里面。<br/>
比如 JVM 里面的垃圾回收线程， 就是典型的使用场景。<br/>
这个场景的特殊之处在于， 当 JVM 进程技术的时候， 内存回收线程存在的意义也就不存在了。<br/>
所以不能因为正在进行垃圾回收导致 JVM 进程无法技术的问题。<br/>
但是守护线程不能用在线程池或者一些 IO 任务的场景里面， 因为一旦 JVM 退出之后， 守护线程也会直接退出。<br/>
就会可能导致任务没有执行完或者资源没有正确释放的问题。



### 如果一个线程两次调用start()，会出现什么问题？

资料来源：[如果一个线程两次调用start()，会出现什么问题？](https://www.toutiao.com/article/7129058773071299103/)

在 Java 里面， 一个线程只能调用一次 start() 方法， 第二次调用会抛出IllegalThreadStateException。
一个线程本身是具备一个生命周期的。
在 Java 里面， 线程的生命周期包括 6 种状态。
**NEW**， 线程被创建还没有调用 start 启动<br/>
**RUNNABLE**， 在这个状态下的线程有可能是正在运行， 也可能是在就绪队列里
面等待操作系统进行调度分配 CPU 资源。<br/>
**BLOCKED**， 线程处于锁等待状态。<br/>
**WAITING**， 表示线程处于条件等待状态， 当触发条件后唤醒， 比如 wait/notify。<br/>
**TIMED_WAIT**， 和 WAITING 状态相同， 只是它多了一个超时条件触发。<br/>
**TERMINATED**， 表示线程执行结束。<br/>
当我们第一次调用 start()方法的时候， 线程的状态可能处于终止或者非 NEW 状态下的其他状态。<br/>
再调用一次 start()， 相当于让这个正在运行的线程重新运行， 不管从线程的安全性角度， 还是从线程本身的执行逻辑， 都是不合理的。<br/>
因此为了避免这个问题， 在线程运行的时候会先判断当前线程的运行状态。<br/>
以上就是我对这个问题的理解

### 面试官：你能说一下什么是受检异常和非受检异常吗？  




### 每天CRUD，日常也不用ThreadLocal啊，为什么面试会问ThreadLocal

资料来源：[每天CRUD，日常也不用ThreadLocal啊，为什么面试会问ThreadLocal](https://www.toutiao.com/video/7084186464350634509/?from_scene=all)<br/>

好的， 这个问题我从三个方面来回答。<br/>
ThreadLocal 是一种线程隔离机制， 它提供了多线程环境下对于共享变量访问的安全性。<br/>
在多线程访问共享变量的场景中， 一般的解决办法是对共享变量加锁， 从而保证在同一时刻只有一个线程能够对共享变量进行更新， 并且基于 Happens-Before
规则里面的监视器锁规则， 又保证了数据修改后对其他线程的可见性。<br/>

![image-20221008140912886](img/image-20221008140912886.png ':size=40%')<br/>
但是加锁会带来性能的下降， 所以 ThreadLocal 用了一种空间换时间的设计思想，<br/>
也就是说在每个线程里面， 都有一个容器来存储共享变量的副本， 然后每个线程只对自己的变量副本来做更新操作， 这样既解决了线程安全问题， 又避免了多线
程竞争加锁的开销<br/>

![image-20221008140952184](img/image-20221008140952184.png ':size=40%')<br/>
ThreadLocal 的 具 体 实 现 原 理 是 ， 在 Thread 类 里 面 有 一 个 成 员 变 量ThreadLocalMap， 它专门来存储当前线程的共享变量副本， 后续这个线程对于共享变量的操作， 都是从这个 ThreadLocalMap 里面进行变更， 不会影响全局共享变量的值。<br/>
以上就是我对这个问题的理解。<br/>
<hr/>

### 谈谈你对AQS的理解

资料来源：[谈谈你对AQS的理解](https://www.toutiao.com/video/7071116552212316708/?from_scene=all)<br/>

QS 是多线程同步器， 它是 J.U.C 包中多个组件的底层实现， 如 Lock、CountDownLatch、 Semaphore 等都用到了 AQS.<br/>
从本质上来说， AQS 提供了两种锁机制， 分别是排它锁， 和共享锁。<br/>
排它锁， 就是存在多线程竞争同一共享资源时， 同一时刻只允许一个线程访问该共享资源， 也就是多个线程中只能有一个线程获得锁资源， 比如 Lock 中的
ReentrantLock 重入锁实现就是用到了 AQS 中的排它锁功能。<br/>
共享锁也称为读锁， 就是在同一时刻允许多个线程同时获得锁资源， 比如CountDownLatch 和 Semaphore 都是用到了 AQS 中的共享锁功能。<br/>



### 多线程篇:@Contended注解有什么用?

资料来源：[多线程篇:@Contended注解有什么用?](https://www.toutiao.com/video/7288592967483261492/?from_scene=all)<br/>

在现代的CPU中，为了提高CPU的利用率，在CPU层面设计了L1、L2、L3三级缓存，缓存以缓存行为单位，进行数据的读取和写入。
缓存行的大小，通常是64个字节。由于多核处理器中的各个核心，在并行执行任务的时候。允许同时读取同一个数据缓存到缓存行中，
那这里就会存在一个潜在的问题，假设存在x/y/z三个变量。占用64个字节空间，当CPU0读取x变量、CPU1读取y变量,CPU0读取x变量的时候，它会一次性的读取64个字节，所以同时会把x/y/z这三个变量都缓存起来，CPU1在读取y变量的时候，也同样会缓存相邻的数据，也会把x/y/z这三个变量都缓存起来。这样在CPU0和CPU1中都缓存了同一份数据。为了保证缓存的一致性，当一个核心修改了一个缓存行中的数据，其他核心的缓存中相同缓存行数据会失效。需要重新从主存中加载最新的数据。那么这个时候问题就出现了。CPU0和Cpu1在不断的竞争同一个缓存行，不断进行失效和重加载。从而导致性能下降。<br/>
这就是所谓的伪共享问题，而@Contented这个注解就可以解决伪共享问题<br/>

#### 问题回答

Contented是java中一个特殊的注解，主要是为了解决伪共享问题<br/>
伪共享是指：在多线程环境下，由于不同线程访问同一缓存行中的不同变量，导致缓存行无效，从而影响程序的性能。为了避免多个线程访问同一个缓存行中的不同变量的问题，可以通过@Contended这个注解来进行修饰，通过这个注解修饰后的变量，可以达到实现缓存行填充的效果。<br/>
也就是如果一个属性，只占用48个字节，Contended注解会继续填充16个字节。从而凑齐64个字节。<br/>
由于缓存行大小是64个字节，所以不同Cpu在加载不同变量的时候。就能够去避免同一个缓存行中出现不同变量的问题。从而去实现缓存行隔离的问题。<br/>
但是在实际使用中我们要注意，这个注解的效果依赖于具体的JVM实现和硬件的构架，而且可能会导致内存占用的增加。在大部分的情况下，合理的内存对齐和数据结构设计是更可靠和高效的伪共享解决<br/>

<hr/>

### AQS 为什么要使用双向链表？  

一 个 工 作 4 年 的 程 序 员 ， 简 历 上 写 精 通 并 发 编 程 ， 并 且 阅 读 过 AQS（AbstractQueuedSynchronizer）的源码， 然后面试官只问了他一个问题， 然后就垮了！<br/>
hi， 大家好， 我是 Mic， 一个没有才华只能靠颜值混饭吃的 Java 程序员。<br/>
AQS 大家都不陌生， 是 J.U.C 包里面一个非常重要的线程同步器。<br/>
面试官提了这样一个问题： “AQS 为什么要采用双向链表结构”？<br/>
下面看看普通人和高手的回答。  <br/>

### 高手
首先， 双向链表的特点是它有两个指针， 一个指针指向前置节点， 一个指针指向后继节点。<br/>
所以， 双向链表可以支持 常量 O(1) 时间复杂度的情况下找到前驱结点， 基于这样的特点。<br/>
双向链表在插入和删除操作的时候， 要比单向链表简单、 高效。<br/>
因此， 从双向链表的特性来看， 我认为 AQS 使用双向链表有三个方面的考虑。<br/>
第一个方面， 没有竞争到锁的线程加入到阻塞队列， 并且阻塞等待的前提是， 当前线程所在节点的前置节点是正常状态， 这样设计是为了避免链表中存在异常线程导致无法唤醒后续线程的问题。  <br/>

所以线程阻塞之前需要判断前置节点的状态， 如果没有指针指向前置节点， 就需要从 head 节点开始遍历， 性能非常低。  <br/>

![image-20231226160450374](img/image-20231226160450374.png)

第二个方面， 在 Lock 接口里面有一个， lockInterruptibly()方法， 这个方法表示处于锁阻塞的线程允许被中断。
也就是说， 没有竞争到锁的线程加入到同步队列等待以后， 是允许外部线程通过interrupt()方法触发唤醒并中断的。
这个时候， 被中断的线程的状态会修改成 CANCELLED。<br/>
被标记为 CANCELLED 状态的线程， 是不需要去竞争锁的， 但是它仍然存在于双向链表里面。<br/>
意味着在后续的锁竞争中， 需要把这个节点从链表里面移除， 否则会导致锁阻塞的线程无法被正常唤醒。
在这种情况下， 如果是单向链表， 就需要从 Head 节点开始往下逐个遍历， 找到并移除异常状态的节点。
同样效率也比较低， 还会导致锁唤醒的操作和遍历操作之间的竞争。  <br/>

![image-20231226160520076](img/image-20231226160520076.png)

第三个方面， 为了避免线程阻塞和唤醒的开销， 所以刚加入到链表的线程， 首先会通过自旋的方式尝试去竞争锁。<br/>
但是实际上按照公平锁的设计， 只有头节点的下一个节点才有必要去竞争锁， 后续的节点竞争锁的意义不大。<br/>
否则， 就会造成羊群效应， 也就是大量的线程在阻塞之前尝试去竞争锁带来比较大的性能开销。<br/>
所以， 为了避免这个问题， 加入到链表中的节点在尝试竞争锁之前， 需要判断前置节点是不是头节点， 如果不是头节点， 就没必要再去触发锁竞争的动作。所以这里会涉及到前置节点的查找， 如果是单向链表， 那么这个功能的实现会非常复杂  <br/>

![image-20231226160555912](img/image-20231226160555912.png)

#### 面试点评
关于这个问题， 99%的人都回答不上来。<br/>
而且我简单翻了一些技术博客， 基本上全都是错的。<br/>
对 AQS 理解不深刻的情况下， 乱回答， 导致很多同学被误解。<br/>
理解一个技术为什么这么设计， 关键在于它需要解决什么样的问题。<br/>
大家记得点赞、 收藏加关注  <br/>

### 这么回答提升30%的面试通过率，ThreadLocal出现内存泄露吗？

文字教程 [「Java」这么回答提升30%的通过率，ThreadLocal出现内存泄露吗？](https://www.toutiao.com/article/7146028552499151393/)

视频教程 [「Java」这么回答提升30%的通过率，ThreadLocal出现内存泄露吗？](https://www.toutiao.com/video/7136849327271608840/)


ThreadLocal是一个用来解决线程安全性问题的工具。

它相当于让每个线程都开辟一块内存空间，用来存储共享变量的副本。

然后每个线程只需要访问和操作自己的共享变量副本即可，从而避免多线程竞争同一个共享资源。

它的工作原理很简单每个线程里面有一个成员变量ThreadLocalMap。

当线程访问用ThreadLocal修饰的共享数据的时候这个线程就会在自己成员变量ThreadLocalMap里面保存一份数据副本。

key指向ThreadLocal这个引用，并且是弱引用关系，而value保存的是共享数据的副本。

因为每个线程都持有一个副本，所以就解决了线程安全性问题。

![3](img/3.png ':size=60%')

这个问题考察的是内存泄漏，所以必然和对象引用有关系。

ThreadLocal中的引用关系如图所示，Thread中的成员变量ThreadLocalMap，它里面的可以key指向ThreadLocal这个成员变量，并且它是一个弱引用所谓弱引用，就是说成员变量ThreadLocal允许在这种引用关系存在的情况下，被GC回收。

一旦被回收，key的引用就变成了null，就会导致这个内存永远无法被访问，造成内存泄漏。

![image-20221008152302427](img/image-20221008152302427.png ':size=50%')

那到底ThreadLocal会不会存在内存泄漏呢？

从ThreadLocal本身的设计上来看，是一定存在的。

可能有些小伙伴忍不住想怼我了，如果这个线程被回收了，那线程里面的成员变量都会被回收。

就不会存在内存泄漏问题啊？

这样理解没问题，但是在实际应用中，我们一般都是使用线程池，而线程池本身是重复利用的所以还是会存在内存泄漏的问题。

除此之外啊，ThreadLocal为了避免内存泄漏问题，当我们在进行数据的读写时，ThreadLocal默认会去尝试做一些清理动作，找到并清理Entry里面key为null的数据。

但是，它仍然不能完全避免，有同学就问了，那怎么办啊！！！

有两个方法可以避免：

- 每次使用完ThreadLocal以后，主动调用remove()方法移除数据
- 把ThreadLocal声明称全局变量，使得它无法被回收

ThreadLocal本身的设计并不复杂，要想深入了解，建议大家去看看源码！


回答：

我认为，不恰当的使用ThreadLocal，会造成内存泄漏问题。

主要原因是，线程的私有变量ThreadLocalMap里面的key是一个弱引用。

弱引用的特性，就是不管是否存在直接引用关系，当成员ThreadLocal没用其他的强引用关系的时候，这个对象会被GC回收掉。

从而导致key可能变成null，造成这块内存永远无法访问，出现内存泄漏的问题。

规避内存泄漏的方法有两个：

通过扩大成员变量ThreadLoca的作用域，避免被GC回收
每次使用完ThreadLocal以后，调用remove方法移除对应的数据
第一种方法虽然不会造成key为null的现象，但是如果后续线程不再继续访问这个key。

也会导致这个内存一直占用不释放，最后造成内存溢出的问题。

所以我认为最好是在使用完以后调用remove方法移除。

<hr/>


### volatile关键字有什么用？它的实现原理是什么？

资料来源：[被面试官问：volatile关键字有什么用？它的实现原理是什么？](https://www.toutiao.com/video/7081951851444503053/)

一个工作了 6 年的 Java 程序员，在阿里二面，被问到“volatile”关键字。
然后，就没有然后了…
同样，另外一个去美团面试的工作 4 年的小伙伴，也被“volatile 关键字“。
然后，也没有然后了…
这个问题说实话，是有点偏底层，但也的确是并发编程里面比较重要的一个关键字。
下面，我们来看看普通人和高手对于这个问题的回答吧。  

#### 普通人
嗯… volatile 可以保证可见性。
#### 高手
volatile 关键字有两个作用。
\1. 可以保证在多线程环境下共享变量的可见性。
\2. 通过增加内存屏障防止多个指令之间的重排序。
我理解的可见性，是指当某一个线程对共享变量的修改，其他线程可以立刻看到修改之
后的值。
其实这个可见性问题，我认为本质上是由几个方面造成的。  




### 并发编程面试请你谈一下CAS机制？如何搞定面试官

资料来源：[【Java面试】并发编程面试请你谈一下CAS机制？如何搞定面试官](https://www.toutiao.com/video/7077490308761682469/)

一个小伙伴私信我，他说遇到了一个关于 CAS 机制的问题，他以为面试官问的是 CAS
实现单点登录。
心想，这个问题我熟啊，然后就按照单点登录的思路去回答，结果面试官一直摇头。
他来和我说，到了面试结束都没明想白自己回答这么好，怎么就没有当场给我发 offer
呢？
实际上，面试官问的是并发编程中的 CAS 机制。
下面我们来看看普通人和高手对于 CAS 机制的回答吧
#### 普通人
CAS，是并发编程中用来实现原子性功能的一种操作，嗯，它类似于一种乐观锁的机制，可以保证并发情况下对共享变量的值的更改的原子性。
嗯， 像 AtomicInteger 这个类中，就用到了 CAS 机制。嗯  

#### 高手
CAS 是 Java 中 Unsafe 类里面的方法，它的全称是 CompareAndSwap，比较并交换的意思。它的主要功能是能够保证在多线程环境下，对于共享变量的修改的原子性。
我来举个例子，比如说有这样一个场景（如图），有一个成员变量 state，默认值是 0，定义了一个方法 doSomething()，这个方法的逻辑是，判断 state 是否为 0 ，如果为0，就修改成 1。
这个逻辑看起来没有任何问题，但是在多线程环境下，会存在原子性的问题，因为这里是一个典型的，Read - Write 的操作。
一般情况下，我们会在 doSomething()这个方法上加同步锁来解决原子性问题。  

![image-20231228102830367](img/image-20231228102830367.png)

但是，加同步锁，会带来性能上的损耗，所以，对于这类场景，我们就可以使用 CAS机制来进行优化
这个是优化之后的代码（如图）
在 doSomething()方法中，我们调用了 unsafe 类中的 compareAndSwapInt()方法来达到同样的目的，这个方法有四个参数，
分别是：当前对象实例、成员变量 state 在内存地址中的偏移量、预期值 0、期望更改之后的值 1。
CAS 机制会比较 state 内存地址偏移量对应的值和传入的预期值 0 是否相等，如果相等，就直接修改内存地址中 state 的值为 1.  

否则，返回 false，表示修改失败，而这个过程是原子的，不会存在线程安全问题。

![image-20231228102914425](img/image-20231228102914425.png)

CompareAndSwap 是一个 native 方法，实际上它最终还是会面临同样的问题，就是先从内存地址中读取 state 的值，然后去比较，最后再修改。
这个过程不管是在什么层面上实现，都会存在原子性问题。
所以呢，CompareAndSwap 的底层实现中，在多核 CPU 环境下，会增加一个 Lock指令对缓存或者总线加锁，从而保证比较并替换这两个指令的原子性。
CAS 主要用在并发场景中，比较典型的使用场景有两个。  

> 1. 第一个是 J.U.C 里面 Atomic 的原子实现，比如 AtomicInteger，AtomicLong。
>
> 2. 第二个是实现多线程对共享资源竞争的互斥性质，比如在 AQS、
>    ConcurrentHashMap、ConcurrentLinkedQueue 等都有用到。
>    以上就是我对这个问题的理解。

#### 结尾
最近大家也发现了我的视频内容在高手回答部分的变化。
有些小伙伴说，你面试怎么还能带图来，明显作弊啊。

## 线程池

### Java官方提供了哪几种线程池，分别有什么特点？

资料来源：[Java官方提供了哪几种线程池，分别有什么特点？](https://www.toutiao.com/video/7123817991153811975/?from_scene=all)

#### 介绍：

> “Java 官方提供了哪几种线程池， 分别有什么特点？ ”
> 这是一道针对工作 3 年左右的面试题， 屏幕前的小伙伴， 你能回答上来吗？  

#### 回答

JDK 中幕刃提供了 5 中不同线程池的创建方式， 下面我分别说一下每一种线程池以及它的特点。<br/>
**newCachedThreadPool**， 是一种可以缓存的线程池， 它可以用来处理大量短期的突发流量。
它的特点有三个， 最大线程数是 Integer.MaxValue， 线程存活时间是 60 秒， 阻塞队列用的是 SynchronousQueue， 这是一种不存才任何元素的阻塞队列， 也就是每提交一个任务给到线程池， 都会分配一个工作线程来处理， 由于最大线程数没有限制。所以它可以处理大量的任务， 另外每个工作线程又可以存活 60s， 使得这些工作线程可以缓存起来应对更多任务的处理。

**newFixedThreadPool**， 是一种固定线程数量的线程池。它的特点是核心线程和最大线程数量都是一个固定的值如果任务比较多工作线程处理不过来， 就会加入到阻塞队列里面等待。

**newSingleThreadExecutor**， 只有一个工作线程的线程池。并且线程数量无法动态更改， 因此可以保证所有的任务都按照 FIFO 的方式顺序执行。

**newScheduledThreadPool**， 具有延迟执行功能的线程池可以用它来实现定时调度

**newWorkStealingPool**， Java8 里面新加入的一个线程池它内部会构建一个 ForkJoinPool， 利用工作窃取的算法并行处理请求。
这些线程都是通过工具类 Executors 来构建的， 线程池的最终实现类是ThreadPoolExecutor。  

### 简述一下你对线程池的理解

资料来源：[简述一下你对线程池的理解](https://www.toutiao.com/video/7123817991153811975/?from_scene=all)

关于这个问题， 我会从几个方面来回答。

首先， 线程池本质上是一种池化技术， 而池化技术是一种资源复用的思想， 比较常见的有连接池、 内存池、 对象池。而线程池里面复用的是线程资源， 它的核心设计目标， 我认为有两个：
减少线程的频繁创建和销毁带来的性能开销， 因为线程创建会涉及到 CPU 上下文切换、 内存分配等工作。
线程池本身会有参数来控制线程创建的数量， 这样就可以避免无休止的创建线程带来的资源利用率过高的问题。

起到了资源保护的作用。
其次， 我简单说一下线程池里面的线程复用技术。 因为线程本身并不是一个受控的技术， 也就是说线程的生命周期时由任务运行的状态决定的， 无法人为控制。所以为了实现线程的复用， 线程池里面用到了阻塞队列， 简单来说就是线程池里面的工作线程处于一直运行状态， 它会从阻塞队列中去获取待执行的任务， 一旦队列空了， 那这个工作线程就会被阻塞， 直到下次有新的任务进来。
也就是说， 工作线程是根据任务的情况实现阻塞和唤醒， 从而达到线程复用的目的。
最后， 线程池里面的资源限制， 是通过几个关键参数来控制的， 分别是核心线程数、 最大线程数。
核心线程数表示默认长期存在的工作线程， 而最大线程数是根据任务的情况动态  

创建的线程， 主要是提高阻塞队列中任务的处理效率。

![image-20221005170022093](img/image-20221005170022093.png ':size=40%')

### 经典高频面试：线程池中的工作线程出现异常怎么办？

资料来源：[【Java面试】经典高频面试：线程池中的工作线程出现异常怎么办？](https://www.toutiao.com/video/7299349908161888777/)

在java中线程池的工作线程出现异常的时候默认会把异常往外抛，同时这个工作线程会因为异常而销毁，我们需要自己去处理对应的异常。

异常处理方法呢有几种

- 1、在传递任务中去处理异常，对于每个提交到线程池中,执行的任务，可以提前通过异常进行捕，这样即便出现了异常，也不会影响线程池的工作线程
- 2、使用Future来获取异常结果
在线程池中提供了一种`submit(Callable<T>)`方法这个方法会返回一个`Future`，我们可以通过调用`Future.get()`方法。来获取任务的执行结果。如果任务执行的过程中出现异常，也会抛出一个`ExecutionException`
其中包含了任务执行过程的的实际异常
- 3、我们可以自定义一个`ThreadFactory`，设置一个叫做`UncaughtExceptionHandler`
我们可以通过实现`ThreadFactory`的接口，来自定义创建线程的方式。然后为每个新创建的线程设置一个`UncaughtExceptionHandler`这个处理器会在线程由于未捕获异常而即将终止的时候被调用

以上就是我对这个问题的理解

### 线程池如何知道一个线程的任务已经执行完成

资料来源：[线程池如何知道一个线程的任务已经执行完成](https://www.toutiao.com/video/7074902532283335199/?channel=&source=video)

一个小伙伴私信了一个小米的面试题，问题是： “线程池如何知道一个线程的任务已经执行完成”？  

说实话，这个问题确实很刁钻，毕竟像很多工作 5 年多的小伙伴，连线程池都没用过，怎么可能回答出来这个问题呢？
下面我们来看看普通人和高手遇到这个问题的回答思路  

#### 普通人
嗯.. （临场发挥吧）

#### 高手

好的，我会从两个方面来回答。

>1. 在线程池内部，当我们把一个任务丢给线程池去执行，线程池会调度工作线程来执行这个任务的 run 方法，run 方法正常结束，也就意味着任务完成了。所以线程池中的工作线程是通过同步调用任务的 run()方法并且等待 run 方法返回后，再去统计任务的完成数量。
> 2. 如果想在线程池外部去获得线程池内部任务的执行状态，有几种方法可以实现。

a. 线程池提供了一个 isTerminated()方法，可以判断线程池的运行状态，我们可以循环判断 isTerminated()方法的返回结果来了解线程池的运行状态，一旦线程池的运行状态是 Terminated，意味着线程池中的所有任务都已经执行完了。

想要通过这个方法获取状态的前提是，程序中主动调用了线程池的 shutdown()方法。在实际业务中，一般不会主动去关闭线程池，因此这个方法在实用性和灵活性方面都不是很好。

b. 在线程池中，有一个 submit()方法，它提供了一个 Future 的返回值，我们通过 Future.get()方法来获得任务的执行结果，当线程池中的任务没执行完之前，future.get()方法会一直阻塞，直到任务执行结束。因此，只要 future.get()方法正常返回，也就意味着传入到线程池中的任务已经执行完成了！

c. 可以引入一个 CountDownLatch 计数器，它可以通过初始化指定一个计数器进行倒计时，其中有两个方法分别是 await()阻塞线程，以及 countDown()进行倒计时，一旦倒计时归零，所以被阻塞在 await()方法的线程都会被释放。
基于这样的原理，我们可以定义一个 CountDownLatch 对象并且计数器为 1，接着在线程池代码块后面调用 await()方法阻塞主线程，然后，当传入到线程池中的任务执行完成后，调用 countDown()方法表示任务执行结束。最后，计数器归零 0，唤醒阻塞在 await()方法的线程。  

### 讲下线程池的线程回收  

资料来源：[【Java面试】用高手的方式回答：线程池的线程回收。直接发offer](https://www.toutiao.com/video/7119375871256822303/?channel=&source=video)

Hi，大家好，我是 Mic，一个工作了 14 年的 Java 程序员。<br/>
最近很多小伙伴私信我，让我说一些线程池相关的问题。<br/>
线程池这个方向考察的点还挺多的，如果只是靠刷面试题<br/>
面试官很容易就能识别出来，我随便举几个。<br/>
-  线程池是如何实现线程的回收的
-  核心线程是否能够回收
-  当调用线程池的 shutdown 方法，会发生什么？
面试一定是连环问，从而确定求职者对这个领域的理解程度。<br/>
关于线程池回收相关的问题，高手部分的回答我整理到了一个 20W 字的面试文档里面大家可以在我的主页加 V 领取。<br/>
下面看看普通人和高手的回答  

#### 高手
好的，面试官，这个问题我需要从 3 个方面来回答。<br/>
首先，线程池里面分为核心线程和非核心线程。<br/>
核心线程是常驻在线程池里面的工作线程，它有两种方式初始化。<br/>

- 向线程池里面添加任务的时候，被动初始化<br/>
- 主动调用 prestartAllCoreThreads 方法<br/>

当线程池里面的队列满了的情况下，为了增加线程池的任务处理能力。<br/>
线程池会增加非核心线程。<br/>
核心线程和非核心线程的数量，是在构造线程池的时候设置的，也可以动态进行更改。<br/>

由于非核心线程是为了解决任务过多的时候临时增加的，所以当任务处理完成后，工作线程处于空闲状态的时候，就需要回收。<br/>
因为所有工作线程都是从阻塞队列中去获取要执行的任务，所以只要在一定时间内，阻塞队列没有任何可以处理的任务，那这个线程就可以结束了。<br/>
这个功能是通过阻塞队列里面的 poll 方法来完成的。这个方法提供了超时时间和超时时间单位这两个参数<br/>
当超过指定时间没有获取到任务的时候，poll 方法返回 null，从而终止当前线程完成线程回收。<br/>

默认情况下，线程池只会回收非核心线程，如果希望核心线程也要回收，可以设置` allowCoreThreadTimeOut `这个属性为` true`，一般情况下我们不会去回收核心线程。<br/>
因为线程池本身就是实现线程的复用，而且这些核心线程在没有任务要处理的时候是处于阻塞状态并没有占用 CPU 资源。<br/>
以上就是我对这个问题的理解。<br/>

#### 面试点评
关于线程池，是每一个 Java 程序员必须要深度掌握的内容。<br/>
它很重要，在我们的应用系统中，无处不在体现线程。<br/>
包括在应用开发中，也难免会用到线程池。<br/>
掌握好它能够写出更加健壮性和稳定性的程序。<br/>
好的，本期的普通人 VS 高手面试系列的视频就到这里结束了<br/>
大家记得点赞、收藏加关注<br/>
我是 Mic，咱们下期再见  <br/>


### 线程池中 shutdown()和 shutdownNow()方法的区别

资料来源：[【Java面试】线程池中 shutdown()和 shutdownNow()方法的区别](https://www.toutiao.com/video/7293790133936095779/?from_scene=all&log_from=e6c2bb38d2fc7_1703576954378)

shutdown()和shutdownNow()这两个方法都是用来关闭线程池的
shutdown()这个方法会使得线程池状态变为关闭状态意味着不再接受新的任务，但是已经提交的任务会继续完成。因此shutdown()并不会立即停止线程池中的工作线程，他只是停止了新任务的提交。一旦所有的任务都执行完成。那么线程池工作线程就会自动退出。

简单来说他是一种优雅停止线程池的方法，在内部的实现中，线程池用到了AQS同步状态，来判断当前是否有正在运行的线程。
shutdown()这个方法在执行线程中断之前，回去竞争这个同步状态，从而去避免强制中端带来的任务执行不完成的风险。

shutdownNow()这个方法他会尝试立即停止所有正在执行的任务，暂停等待的任务，并不会立即停止线程池中的工作线程
返回正在等待执行的列表。在内部的实现中呢，他是通过调用线程的interrupt()方法来停止线程的，这个方法依赖于工作线程对于这个终端的相应特性。
不保证能够立即停止正在执行的任务。但是会尽力去做。所以这个方法类似于一种暴力停机的实现。所以在实际开发的过程中
尽可能使用shutdow()这个方法，去保证线程池的优雅中断。来确保任务的完成性。

以上就是我对这个问题的理解