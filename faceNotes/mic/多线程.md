## 线程

### 谈谈你对线程安全的理解

资料来源：[谈谈你对线程安全的理解](https://www.toutiao.com/video/7085655943110722062/?from_scene=all)

Hi， 大家好， 我是 Mic
一个工作了 4 年的小伙伴， 遇到了一个非常抽象的面试题， 说说你对线程安全性
的理解。
这类问题， 对于临时刷面试题来面试的小伙伴， 往往是致命的。
一个是不知道从何说起， 也就是语言组织比较困难。
其次就是， 如果对于线程安全性没有一定程度的理解， 一般很难说出你的理解。
ok， 我们来看看这个问题的回答。  

#### 高手

简单来说， 在多个线程访问某个方法或者对象的时候， 不管通过任何的方式调用以及线程如何去交替执行。
在程序中不做任何同步干预操作的情况下， 这个方法或者对象的执行/修改都能按照预期的结果来反馈， 那么这个类就是线程安全的。
实际上， 线程安全问题的具体表现体现在三个方面， 原子性、 有序性、 可见性。
原子性呢， 是指当一个线程执行一系列程序指令操作的时候， 它应该是不可中断的， 因为一旦出现中断， 站在多线程的视角来看， 这一系列的程序指令会出现前后执行结果不一致的问题。
这个和数据库里面的原子性是一样的， 简单来说就是一段程序只能由一个线程完整的执行完成， 而不能存在多个线程干扰。
CPU 的 上 下 文 切 换 ， 是 导 致 原 子 性 问 题 的 核 心 ， 而 JVM 里 面 提 供 了Synchronized 关键字来解决原子性问题  

![image-20231225153939801](img/image-20231225153939801.png)

可见性， 就是说在多线程环境下， 由于读和写是发生在不同的线程里面， 有可能出现某个线程对共享变量的修改， 对其他线程不是实时可见的。
导致可见性问题的原因有很多， 比如 CPU 的高速缓存、 CPU 的指令重排序、 编译器的指令重排序。
有序性， 指的是程序编写的指令顺序和最终 CPU 运行的指令顺序可能出现不一致的现象， 这种现象也可以称为指令重排序， 所以有序性也会导致可见性问题。
可见性和有序性可以通过 JVM 里面提供了一个 Volatile 关键字来解决。
在我看来， 导致有序性、 原子性、 可见性问题的本质， 是计算机工程师为了最大化提升 CPU 利用率导致的。 比如为了提升 CPU 利用率， 设计了三级缓存、 设计了 StoreBuffer、 设计了缓存行这种预读机制、 在操作系统里面， 设计了线程模型、 在编译器里面， 设计了编译器的深度优化机制。
一上就是我对这个问题的理解。  

#### 面试点评

从高手的回答中， 可以很深刻的感受到， 他对于计算机底层原理和线程安全性相
关的底层实现是理解得很透彻的。

对我来说， 这个人去写程序代码， 不用担心他滥用线程导致一些不可预测的线程安全性问题了， 这就是这个面试题的价值。
好的， 本期的普通人 VS 高手面试系列的视频就到这里结束了， 喜欢的朋友记得点赞和收藏。
另外， 这些面试题我都整理成了笔记， 大家有需要的可以私信获取。
我是 Mic， 一个工作了 14 年的 Java 程序员， 咱们下期再见  

### 什么是守护线程，它有什么特点？

资料来源：[什么是守护线程，它有什么特点？](https://www.toutiao.com/video/7101505375253299748/?from_scene=all)

守护线程， 它是一种专门为用户线程提供服务的线程， 它的生命周期依赖于用户线程。<br/>
只有 JVM 中仍然还存在用户线程正在运行的情况下， 守护线程才会有存在的意义。<br/>
否则， 一旦 JVM 进程结束， 那守护线程也会随之结束。<br/>
也就是说， 守护线程不会阻止 JVM 的退出。 但是用户线程会！<br/>
守护线程和用户线程的创建方式是完全相同的， 我们只需要调用用户线程里面的setDaemon 方法并且设置成 true， 就表示这个线程是守护线程。<br/>
因为守护线程拥有自己结束自己生命的特性， 所以它适合用在一些后台的通用服务场景里面。<br/>
比如 JVM 里面的垃圾回收线程， 就是典型的使用场景。<br/>
这个场景的特殊之处在于， 当 JVM 进程技术的时候， 内存回收线程存在的意义也就不存在了。<br/>
所以不能因为正在进行垃圾回收导致 JVM 进程无法技术的问题。<br/>
但是守护线程不能用在线程池或者一些 IO 任务的场景里面， 因为一旦 JVM 退出之后， 守护线程也会直接退出。<br/>
就会可能导致任务没有执行完或者资源没有正确释放的问题。



### 如果一个线程两次调用start()，会出现什么问题？

资料来源：[如果一个线程两次调用start()，会出现什么问题？](https://www.toutiao.com/article/7129058773071299103/)

在 Java 里面， 一个线程只能调用一次 start() 方法， 第二次调用会抛出IllegalThreadStateException。
一个线程本身是具备一个生命周期的。
在 Java 里面， 线程的生命周期包括 6 种状态。
**NEW**， 线程被创建还没有调用 start 启动<br/>
**RUNNABLE**， 在这个状态下的线程有可能是正在运行， 也可能是在就绪队列里
面等待操作系统进行调度分配 CPU 资源。<br/>
**BLOCKED**， 线程处于锁等待状态。<br/>
**WAITING**， 表示线程处于条件等待状态， 当触发条件后唤醒， 比如 wait/notify。<br/>
**TIMED_WAIT**， 和 WAITING 状态相同， 只是它多了一个超时条件触发。<br/>
**TERMINATED**， 表示线程执行结束。<br/>
当我们第一次调用 start()方法的时候， 线程的状态可能处于终止或者非 NEW 状态下的其他状态。<br/>
再调用一次 start()， 相当于让这个正在运行的线程重新运行， 不管从线程的安全性角度， 还是从线程本身的执行逻辑， 都是不合理的。<br/>
因此为了避免这个问题， 在线程运行的时候会先判断当前线程的运行状态。<br/>
以上就是我对这个问题的理解
<hr/>

### 答对轻松拿offer说一下你对CompletableFuture的理解

资料来源：[答对轻松拿offer说一下你对CompletableFuture的理解](https://www.toutiao.com/video/7104141316065329700/)

<hr/>

### wait和sleep是否会触发锁的释放以及CPU资源的释放？

资料来源：[【Java面试】wait和sleep是否会触发锁的释放以及CPU资源的释放？](https://www.toutiao.com/video/7112384560884613640/?from_scene=all)

<hr/>


### 你能说一下什么是受检异常和非受检异常吗？  

资料来源：[ 面试官：你能说一下什么是受检异常和非受检异常吗？  ](https://www.toutiao.com/video/7098229963794416159/?channel=&source=video)


### 面试被问到并发编程中，如何中断一个正在运行中的线程？
资料来源：[ 面试被问到并发编程中，如何中断一个正在运行中的线程？  ](https://www.toutiao.com/video/7097845498283262494/)

<hr/>

### 每天CRUD，日常也不用ThreadLocal啊，为什么面试会问ThreadLocal

资料来源：[每天CRUD，日常也不用ThreadLocal啊，为什么面试会问ThreadLocal](https://www.toutiao.com/video/7084186464350634509/?from_scene=all)<br/>

好的， 这个问题我从三个方面来回答。<br/>
ThreadLocal 是一种线程隔离机制， 它提供了多线程环境下对于共享变量访问的安全性。<br/>
在多线程访问共享变量的场景中， 一般的解决办法是对共享变量加锁， 从而保证在同一时刻只有一个线程能够对共享变量进行更新， 并且基于 Happens-Before
规则里面的监视器锁规则， 又保证了数据修改后对其他线程的可见性。<br/>

![image-20221008140912886](img/image-20221008140912886.png ':size=40%')<br/>
但是加锁会带来性能的下降， 所以 ThreadLocal 用了一种空间换时间的设计思想，<br/>
也就是说在每个线程里面， 都有一个容器来存储共享变量的副本， 然后每个线程只对自己的变量副本来做更新操作， 这样既解决了线程安全问题， 又避免了多线
程竞争加锁的开销<br/>

![image-20221008140952184](img/image-20221008140952184.png ':size=40%')<br/>
ThreadLocal 的 具 体 实 现 原 理 是 ， 在 Thread 类 里 面 有 一 个 成 员 变 量ThreadLocalMap， 它专门来存储当前线程的共享变量副本， 后续这个线程对于共享变量的操作， 都是从这个 ThreadLocalMap 里面进行变更， 不会影响全局共享变量的值。<br/>
以上就是我对这个问题的理解。<br/>
<hr/>

### 谈谈你对AQS的理解

资料来源：[谈谈你对AQS的理解](https://www.toutiao.com/video/7071116552212316708/?from_scene=all)<br/>

QS 是多线程同步器， 它是 J.U.C 包中多个组件的底层实现， 如 Lock、CountDownLatch、 Semaphore 等都用到了 AQS.<br/>
从本质上来说， AQS 提供了两种锁机制， 分别是排它锁， 和共享锁。<br/>
排它锁， 就是存在多线程竞争同一共享资源时， 同一时刻只允许一个线程访问该共享资源， 也就是多个线程中只能有一个线程获得锁资源， 比如 Lock 中的
ReentrantLock 重入锁实现就是用到了 AQS 中的排它锁功能。<br/>
共享锁也称为读锁， 就是在同一时刻允许多个线程同时获得锁资源， 比如CountDownLatch 和 Semaphore 都是用到了 AQS 中的共享锁功能。<br/>

<hr/>

### 多线程篇:@Contended注解有什么用?

资料来源：[多线程篇:@Contended注解有什么用?](https://www.toutiao.com/video/7288592967483261492/?from_scene=all)<br/>

在现代的CPU中，为了提高CPU的利用率，在CPU层面设计了L1、L2、L3三级缓存，缓存以缓存行为单位，进行数据的读取和写入。
缓存行的大小，通常是64个字节。由于多核处理器中的各个核心，在并行执行任务的时候。允许同时读取同一个数据缓存到缓存行中，
那这里就会存在一个潜在的问题，假设存在x/y/z三个变量。占用64个字节空间，当CPU0读取x变量、CPU1读取y变量,CPU0读取x变量的时候，它会一次性的读取64个字节，所以同时会把x/y/z这三个变量都缓存起来，CPU1在读取y变量的时候，也同样会缓存相邻的数据，也会把x/y/z这三个变量都缓存起来。这样在CPU0和CPU1中都缓存了同一份数据。为了保证缓存的一致性，当一个核心修改了一个缓存行中的数据，其他核心的缓存中相同缓存行数据会失效。需要重新从主存中加载最新的数据。那么这个时候问题就出现了。CPU0和Cpu1在不断的竞争同一个缓存行，不断进行失效和重加载。从而导致性能下降。<br/>
这就是所谓的伪共享问题，而@Contented这个注解就可以解决伪共享问题<br/>

#### 问题回答

Contented是java中一个特殊的注解，主要是为了解决伪共享问题<br/>
伪共享是指：在多线程环境下，由于不同线程访问同一缓存行中的不同变量，导致缓存行无效，从而影响程序的性能。为了避免多个线程访问同一个缓存行中的不同变量的问题，可以通过@Contended这个注解来进行修饰，通过这个注解修饰后的变量，可以达到实现缓存行填充的效果。<br/>
也就是如果一个属性，只占用48个字节，Contended注解会继续填充16个字节。从而凑齐64个字节。<br/>
由于缓存行大小是64个字节，所以不同Cpu在加载不同变量的时候。就能够去避免同一个缓存行中出现不同变量的问题。从而去实现缓存行隔离的问题。<br/>
但是在实际使用中我们要注意，这个注解的效果依赖于具体的JVM实现和硬件的构架，而且可能会导致内存占用的增加。在大部分的情况下，合理的内存对齐和数据结构设计是更可靠和高效的伪共享解决<br/>

<hr/>

### AQS 为什么要使用双向链表？  

一 个 工 作 4 年 的 程 序 员 ， 简 历 上 写 精 通 并 发 编 程 ， 并 且 阅 读 过 AQS（AbstractQueuedSynchronizer）的源码， 然后面试官只问了他一个问题， 然后就垮了！<br/>
hi， 大家好， 我是 Mic， 一个没有才华只能靠颜值混饭吃的 Java 程序员。<br/>
AQS 大家都不陌生， 是 J.U.C 包里面一个非常重要的线程同步器。<br/>
面试官提了这样一个问题： “AQS 为什么要采用双向链表结构”？<br/>
下面看看普通人和高手的回答。  <br/>

#### 高手
首先， 双向链表的特点是它有两个指针， 一个指针指向前置节点， 一个指针指向后继节点。<br/>
所以， 双向链表可以支持 常量 O(1) 时间复杂度的情况下找到前驱结点， 基于这样的特点。<br/>
双向链表在插入和删除操作的时候， 要比单向链表简单、 高效。<br/>
因此， 从双向链表的特性来看， 我认为 AQS 使用双向链表有三个方面的考虑。<br/>
第一个方面， 没有竞争到锁的线程加入到阻塞队列， 并且阻塞等待的前提是， 当前线程所在节点的前置节点是正常状态， 这样设计是为了避免链表中存在异常线程导致无法唤醒后续线程的问题。  <br/>

所以线程阻塞之前需要判断前置节点的状态， 如果没有指针指向前置节点， 就需要从 head 节点开始遍历， 性能非常低。  <br/>

![image-20231226160450374](img/image-20231226160450374.png)

第二个方面， 在 Lock 接口里面有一个， lockInterruptibly()方法， 这个方法表示处于锁阻塞的线程允许被中断。
也就是说， 没有竞争到锁的线程加入到同步队列等待以后， 是允许外部线程通过interrupt()方法触发唤醒并中断的。
这个时候， 被中断的线程的状态会修改成 CANCELLED。<br/>
被标记为 CANCELLED 状态的线程， 是不需要去竞争锁的， 但是它仍然存在于双向链表里面。<br/>
意味着在后续的锁竞争中， 需要把这个节点从链表里面移除， 否则会导致锁阻塞的线程无法被正常唤醒。
在这种情况下， 如果是单向链表， 就需要从 Head 节点开始往下逐个遍历， 找到并移除异常状态的节点。
同样效率也比较低， 还会导致锁唤醒的操作和遍历操作之间的竞争。  <br/>

![image-20231226160520076](img/image-20231226160520076.png)

第三个方面， 为了避免线程阻塞和唤醒的开销， 所以刚加入到链表的线程， 首先会通过自旋的方式尝试去竞争锁。<br/>
但是实际上按照公平锁的设计， 只有头节点的下一个节点才有必要去竞争锁， 后续的节点竞争锁的意义不大。<br/>
否则， 就会造成羊群效应， 也就是大量的线程在阻塞之前尝试去竞争锁带来比较大的性能开销。<br/>
所以， 为了避免这个问题， 加入到链表中的节点在尝试竞争锁之前， 需要判断前置节点是不是头节点， 如果不是头节点， 就没必要再去触发锁竞争的动作。所以这里会涉及到前置节点的查找， 如果是单向链表， 那么这个功能的实现会非常复杂  <br/>

![image-20231226160555912](img/image-20231226160555912.png)

#### 面试点评
关于这个问题， 99%的人都回答不上来。<br/>
而且我简单翻了一些技术博客， 基本上全都是错的。<br/>
对 AQS 理解不深刻的情况下， 乱回答， 导致很多同学被误解。<br/>
理解一个技术为什么这么设计， 关键在于它需要解决什么样的问题。<br/>
大家记得点赞、 收藏加关注  <br/>



###  请说一下ReentrantLock的实现原理？
视频教程 [请说一下ReentrantLock的实现原理？](https://www.toutiao.com/video/7091925659584463373/?from_scene=all)


<hr/>


### 面试被问lock和synchronized的区别，如何回答轻松搞定面试官
视频教程 [ 面试被问lock和synchronized的区别，如何回答轻松搞定面试官](https://www.toutiao.com/video/7074150041119621646/?from_scene=all)

<hr/>


### 这么回答提升30%的面试通过率，ThreadLocal出现内存泄露吗？

文字教程 [「Java」这么回答提升30%的通过率，ThreadLocal出现内存泄露吗？](https://www.toutiao.com/article/7146028552499151393/)

视频教程 [「Java」这么回答提升30%的通过率，ThreadLocal出现内存泄露吗？](https://www.toutiao.com/video/7136849327271608840/)


ThreadLocal是一个用来解决线程安全性问题的工具。

它相当于让每个线程都开辟一块内存空间，用来存储共享变量的副本。

然后每个线程只需要访问和操作自己的共享变量副本即可，从而避免多线程竞争同一个共享资源。

它的工作原理很简单每个线程里面有一个成员变量ThreadLocalMap。

当线程访问用ThreadLocal修饰的共享数据的时候这个线程就会在自己成员变量ThreadLocalMap里面保存一份数据副本。

key指向ThreadLocal这个引用，并且是弱引用关系，而value保存的是共享数据的副本。

因为每个线程都持有一个副本，所以就解决了线程安全性问题。

![3](img/3.png ':size=60%')

这个问题考察的是内存泄漏，所以必然和对象引用有关系。

ThreadLocal中的引用关系如图所示，Thread中的成员变量ThreadLocalMap，它里面的可以key指向ThreadLocal这个成员变量，并且它是一个弱引用所谓弱引用，就是说成员变量ThreadLocal允许在这种引用关系存在的情况下，被GC回收。

一旦被回收，key的引用就变成了null，就会导致这个内存永远无法被访问，造成内存泄漏。

![image-20221008152302427](img/image-20221008152302427.png ':size=50%')

那到底ThreadLocal会不会存在内存泄漏呢？

从ThreadLocal本身的设计上来看，是一定存在的。

可能有些小伙伴忍不住想怼我了，如果这个线程被回收了，那线程里面的成员变量都会被回收。

就不会存在内存泄漏问题啊？

这样理解没问题，但是在实际应用中，我们一般都是使用线程池，而线程池本身是重复利用的所以还是会存在内存泄漏的问题。

除此之外啊，ThreadLocal为了避免内存泄漏问题，当我们在进行数据的读写时，ThreadLocal默认会去尝试做一些清理动作，找到并清理Entry里面key为null的数据。

但是，它仍然不能完全避免，有同学就问了，那怎么办啊！！！

有两个方法可以避免：

- 每次使用完ThreadLocal以后，主动调用remove()方法移除数据
- 把ThreadLocal声明称全局变量，使得它无法被回收

ThreadLocal本身的设计并不复杂，要想深入了解，建议大家去看看源码！


回答：

我认为，不恰当的使用ThreadLocal，会造成内存泄漏问题。

主要原因是，线程的私有变量ThreadLocalMap里面的key是一个弱引用。

弱引用的特性，就是不管是否存在直接引用关系，当成员ThreadLocal没用其他的强引用关系的时候，这个对象会被GC回收掉。

从而导致key可能变成null，造成这块内存永远无法访问，出现内存泄漏的问题。

规避内存泄漏的方法有两个：

通过扩大成员变量ThreadLoca的作用域，避免被GC回收
每次使用完ThreadLocal以后，调用remove方法移除对应的数据
第一种方法虽然不会造成key为null的现象，但是如果后续线程不再继续访问这个key。

也会导致这个内存一直占用不释放，最后造成内存溢出的问题。

所以我认为最好是在使用完以后调用remove方法移除。

<hr/>


### volatile关键字有什么用？它的实现原理是什么？

资料来源：[被面试官问：volatile关键字有什么用？它的实现原理是什么？](https://www.toutiao.com/video/7081951851444503053/)

一个工作了 6 年的 Java 程序员，在阿里二面，被问到“volatile”关键字。<br/>
然后，就没有然后了…<br/>
同样，另外一个去美团面试的工作 4 年的小伙伴，也被“volatile 关键字“。<br/>
然后，也没有然后了…<br/>
这个问题说实话，是有点偏底层，但也的确是并发编程里面比较重要的一个关键字。<br/>
下面，我们来看看普通人和高手对于这个问题的回答吧。  <br/>

#### 普通人

嗯… volatile 可以保证可见性。

#### 高手
volatile 关键字有两个作用。
- 1. 可以保证在多线程环境下共享变量的可见性。<br/>
- 2. 通过增加内存屏障防止多个指令之间的重排序。<br/>

我理解的可见性，是指当某一个线程对共享变量的修改，其他线程可以立刻看到修改之后的值。<br/>
其实这个可见性问题，我认为本质上是由几个方面造成的。  




### 并发编程面试请你谈一下CAS机制？如何搞定面试官

资料来源：[【Java面试】并发编程面试请你谈一下CAS机制？如何搞定面试官](https://www.toutiao.com/video/7077490308761682469/)

一个小伙伴私信我，他说遇到了一个关于 CAS 机制的问题，他以为面试官问的是 CAS
实现单点登录。
心想，这个问题我熟啊，然后就按照单点登录的思路去回答，结果面试官一直摇头。
他来和我说，到了面试结束都没明想白自己回答这么好，怎么就没有当场给我发 offer
呢？
实际上，面试官问的是并发编程中的 CAS 机制。
下面我们来看看普通人和高手对于 CAS 机制的回答吧
#### 普通人
CAS，是并发编程中用来实现原子性功能的一种操作，嗯，它类似于一种乐观锁的机制，可以保证并发情况下对共享变量的值的更改的原子性。
嗯， 像 AtomicInteger 这个类中，就用到了 CAS 机制。嗯  

#### 高手
CAS 是 Java 中 Unsafe 类里面的方法，它的全称是 CompareAndSwap，比较并交换的意思。它的主要功能是能够保证在多线程环境下，对于共享变量的修改的原子性。
我来举个例子，比如说有这样一个场景（如图），有一个成员变量 state，默认值是 0，定义了一个方法 doSomething()，这个方法的逻辑是，判断 state 是否为 0 ，如果为0，就修改成 1。
这个逻辑看起来没有任何问题，但是在多线程环境下，会存在原子性的问题，因为这里是一个典型的，Read - Write 的操作。
一般情况下，我们会在 doSomething()这个方法上加同步锁来解决原子性问题。  

![image-20231228102830367](img/image-20231228102830367.png)

但是，加同步锁，会带来性能上的损耗，所以，对于这类场景，我们就可以使用 CAS机制来进行优化
这个是优化之后的代码（如图）
在 doSomething()方法中，我们调用了 unsafe 类中的 compareAndSwapInt()方法来达到同样的目的，这个方法有四个参数，
分别是：当前对象实例、成员变量 state 在内存地址中的偏移量、预期值 0、期望更改之后的值 1。
CAS 机制会比较 state 内存地址偏移量对应的值和传入的预期值 0 是否相等，如果相等，就直接修改内存地址中 state 的值为 1.  

否则，返回 false，表示修改失败，而这个过程是原子的，不会存在线程安全问题。

![image-20231228102914425](img/image-20231228102914425.png)

CompareAndSwap 是一个 native 方法，实际上它最终还是会面临同样的问题，就是先从内存地址中读取 state 的值，然后去比较，最后再修改。
这个过程不管是在什么层面上实现，都会存在原子性问题。
所以呢，CompareAndSwap 的底层实现中，在多核 CPU 环境下，会增加一个 Lock指令对缓存或者总线加锁，从而保证比较并替换这两个指令的原子性。
CAS 主要用在并发场景中，比较典型的使用场景有两个。  

> 1. 第一个是 J.U.C 里面 Atomic 的原子实现，比如 AtomicInteger，AtomicLong。
>
> 2. 第二个是实现多线程对共享资源竞争的互斥性质，比如在 AQS、ConcurrentHashMap、ConcurrentLinkedQueue 等都有用到。

 以上就是我对这个问题的理解。

#### 结尾
最近大家也发现了我的视频内容在高手回答部分的变化。
有些小伙伴说，你面试怎么还能带图来，明显作弊啊。


### wait和sleep是否会触发锁的释放以及CPU资源的释放？
资料来源：[【Java面试】wait和sleep是否会触发锁的释放以及CPU资源的释放？](https://www.toutiao.com/video/7112384560884613640/?from_scene=all)



### 日常也不用ThreadLocal啊，为什么面试会问ThreadLocal
资料来源：[每天CRUD，日常也不用ThreadLocal啊，为什么面试会问ThreadLocal](https://www.toutiao.com/video/7084186464350634509/?from_scene=all)



